# Задание Анализ лога веб-сервера

# Цель

Потренироваться писать парсеры для логов.

link to regex https://regex101.com/r/xDfSqj/4

# Принцип работы

Путем указания аргументом cmd скрипту путь до файла(любого) происходит его чтение(насколько это возможно) и последовательное выполнение команд:
1. Создается переменная с регулярным выражением.
2. Создается пустой log_data и в последствии наполняется упорядоченными словарями.
3. При помощи Counter - создаются генераторы
4. При помощи nlargest - вычисляется топ самых долгих запроса(без учета их количества, количество определяется в другом месте).
5. for i in sorted(group_files, reverse=False, key=lambda x: x['time_micro'])[:3] - Здесь я воспользовался советом со stackowf, так как закусился с ошибкой.
6. Выполняю вывод полученных результатов в консоль попутно записывая значения в заранее созданные словари.
7. Формирую json dict для дальнейшего json.dump в файл
8. Пишу в json файл.
7. Я в задание прикреплю скриншоты с построчным описанием.

# Запуск
Находясь в папке с исполняемым файлом, например ~/repo/otus-logs/ выполнить команду:
/${Path_to_python_script}/simple_test.py /${Path_to_log_file}/access.log
Путь в лог файлу может быть любой, json файл сгенерируется в корень проекта.